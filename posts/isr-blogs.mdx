
**Introduction**

- This section will briefly introduce the reader to the labours and pitfalls of publishing and maintaining technical content on both a third-party platform and their personal website.
- By the end of the article the reader will have learned how to streamline their process and publish to - and maintain - both platforms from a single source of truth.

## The problem

- Writing the blog post in a note-taking app
- Submitting the blog post as an exported doc for review
- Cloning the article into mdx for my website
- Easy to fall out of sync
- Updates need to be made in multiple places

## The solution

- Writing the article in Notion
- Sharing the article with the LogRocket team for review / Publishing on LogRocket
- Publishing the article on the personal site
- Updates are only ever made to the Notion article.
- LogRocket team are notified of changes, and ISR automatically updates the site content
- Notion considered working source of truth. LogRocket considered published source of truth

## Notion


Notion is a productivity tool with a suite of features designed for real-time collaboration. It can be used by individuals as a traditional note-taking app, through to large enterprise teams using databases and project management tools to organise and document.


For the purposes of this article, we will be creating an index page for professional blog posts. The page will use a database to store relevant articles and any associated frontmatter. Each row in the database will link to a subpage, containing the article’s content. 


We’ll start by creating a new page in Notion and selecting the Table template. With the table created, we’ll select the `+ New Database` option from the Data Source menu to create a blank table on the page. The table will hold frontmatter information about the article, and a link to the subpage containing the article’s content.


 


| Column    | Description                                                                   |
| --------- | ----------------------------------------------------------------------------- |
| published | A checkbox that will control whether the page displays on the personal site   |
| page      | A link to a subpage containing the article content                            |
| canonical | A link to the published LogRocket article, considering it the source of truth |
| abstract  | A short description of the article. Useful for meta tags and blog cards       |
| date      | The date the article was published                                            |
| tags      | An array of tags that can be used to filter the articles on the personal site |
| slug      | A unique identifier for each post, used for the URL routing on the website    |


The published column allows us to write new articles in Notion without them appearing on the website prematurely. When the personal website is retrieving posts using the Notion API, it will filter any results where the published column is unchecked. This also allows the article to be published on LogRocket for a brief period of time before going live on the website. 


The page column contains a link to the subpage with the article’s content. We’ll use this to retrieve the content blocks for the article later. Once the article has been live for a couple of weeks, the LogRocket URL is added to the canonical column and the published column is checked. 


| Published | Page                                      | Canonical                                   |
| --------- | ----------------------------------------- | ------------------------------------------- |
| [ x ]     | <u>Building an Accessible Menubar…</u>    | https://blog.logrocket.com/building-menubar |
| [    ]    | <u>Streamline Your Technical Writing…</u> |                                             |


The remaining columns are exclusively for the benefit of the personal site. The published date allows the articles to be sorted into chronological order, and the tags enable the user to filter the articles on the `/writing` page. The abstract provides a short description of the article for the blog preview component and metadata for sharing. Finally, The slug is used as the unique address for each post `/writing/<slug>`. 


| Date       | Tags           | Abstract                                | Slug               |
| ---------- | -------------- | --------------------------------------- | ------------------ |
| 01/04/2021 | react, a11y    | How to create an accessible menubar…    | accessible-menubar |
| 27/09/2021 | react, dev rel | Streamline your technical writing with… | technical-writing  |


With the data correctly structured, we can look to publish the posts on our personal website. 


**Notion: API**

- This section will introduce the reader to the [Notion API](https://developers.notion.com/). By the end of the section, the reader will be able to configure their NextJS website to retrieve a collection of posts created in the previous paragraphs. This will include page frontmatter for the blog overview page, and individual page content for the articles themselves.

In previous iterations, I would have manually copied and pasted the content into a markdown or mdx file. This works, but is tedious and prone to human error. It also makes it difficult to track the single source of truth. There’s no way of guaranteeing that the latest version of each post is live on your website, other than manually copying and pasting the pages over each time. 


Instead, we can harness the Notion API to automate this task for us.  To accomplish this, we’ll need the content database that we created earlier, a client to retrieve posts on our personal website, and a custom [integration](https://www.notion.so/integrations/all) in Notion to authenticate the requests.


Let’s start by creating an integration that will allow our personal website to communicate with our workspace. Open the [My Integrations](https://www.notion.so/my-integrations) page in Notion and select **Create New Integration**. Since the integration will be private and not hosted on Notion’s Integration page, we can select Internal Integration. After naming the integration and associating it with your workspace, select **Read Content** from the _Content Capabilities_, and check the **No user information** radio button in _User Capabilities_. All _Comment Capabilities_ options can remain unchecked. This will permit the website to retrieve the content without any unnecessary permissions.


![](https://i.imgur.com/Y5LQLkn.png)


We’ll need two environment variables in our Next JS project to authenticate and retrieve the database content. The first is the Internal Integration Token, which can be found once your integration has been created.  


**NOTE:** The token and database ID values presented below are dummy values for the purposes of this article. These values should not be shared outside of your Vercel project dashboard and local environment file.


	![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/73d0ee3e-b8f5-4ec5-9034-ccccb0590e00/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230313%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230313T131037Z&X-Amz-Expires=3600&X-Amz-Signature=e6904c622d333a77ecff5876f4ea39c7aa99278d0f2d7b37e5fc005175d63502&X-Amz-SignedHeaders=host&x-id=GetObject)


The second is the database ID. You can find this between the workspace and the view ID in the url:


```text
https://www.notion.so/<WORKSPACE>/**<DATABASE_ID>**?
https://www.notion.so/phunkren/**9d7344da8c66c9a7487577735b83141c**?
```


Let’s add both of these values to our local environment, and on our Next JS environments:



```text
/* .env.local */

NOTION_INTERNAL_INTEGRATION_TOKEN=secret_hIGy3ihYFspwW8UwcRPJqKuMFa5HQB8YYWIwuNpNvg8
NOTION_DATABASE_ID=9d7344da8c66c9a7487577735b83141c
```


![](https://s3.us-west-2.amazonaws.com/secure.notion-static.com/1d98658d-71b2-4811-8cfd-497dfae1ec0a/vercel.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20230313%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20230313T131031Z&X-Amz-Expires=3600&X-Amz-Signature=ce2c91c34610ea4edc7ddb526b96328a3f346cc52e2419dd9131dda9b3127167&X-Amz-SignedHeaders=host&x-id=GetObject)


Next we’ll head over to the website codebase to create an interface to interact with Notion in our Next JS project. We’ll start by creating a new Client instance from the [notionhq/client](https://www.npmjs.com/package/@notionhq/client) library 



```typescript
/* lib/notion.ts */
import { Client } from "@notionhq/client";

const notionClient = new Client({
  auth: process.env.NOTION_INTERNAL_INTEGRATION_TOKEN,
});
```


With an authenticated client, we can now make requests to retrieve the content from the database. 


```typescript
/* lib/notion.ts */

async function getPosts(databaseId) {
  const response = await notionClient.databases.query({
    database_id: databaseId,
  });

  return response.results;
};
```


If we inspect the results, you’ll notice that Notion downloads each chunk of content in a [block](https://developers.notion.com/reference/block). A block is an object containing the raw content and metadata for each chunk. While it is possible to deconstruct each of these blogs using the API documentation, I prefer to use a third-party wrapper, [notion-to-md](https://www.npmjs.com/package/notion-to-md). The package is somewhat literal, in that it will take a collection of Notion blocks and convert it into a markdown file. 


Let’s add a function that takes the results of the `getPosts` function and generates a markdown file for each result. We’ll store each file in the `posts` directory, and use the `slug` property as the file name.


To convert the Notion blocks to markdown blocks, let’s create an `n2m` client by passing the `notionClient` we created earlier as a parameter to the `NotionToMarkdown` module. With the content converted, we’ll use the same module to convert the markdown blocks () into a markdown string. 


All that’s left is to create the file for each post, using the post’s slug as it’s file name, and populate it with the newly-created markdown string.


```typescript
/* lib/notion.js */
import { NotionToMarkdown } from "notion-to-md";

const n2m = new NotionToMarkdown({ notionClient });

export async function createPosts(posts) {
  for (const post of posts) {
    const uuid = post.id;
    const slug = post.properties.slug.rich_text[0].plain_text;
    const mdblocks = await n2m.pageToMarkdown(uuid);
    const mdString = n2m.toMarkdownString(mdblocks);
    const filename = `${POSTS_DIR}/${slug}.mdx`;

    fs.writeFile(filename, mdString, (err) => {
      err !== null && console.log(err);
    });
  }
}
```


**Website - Display all posts**


The homepage will display a list of all blog posts from the database. Each list item will contain descriptive information about the blog, with a link to navigate to the post itself.


Since all of the information is available at build time, we can fetch the data using the `getStaticProps` function, and pass the results to the client in the `props` object. This allows us to request data using sensitive information without making it available on the client. 


Once the posts have been successfully fetched, we’ll use some utility functions to filter any unpublished articles from the returned results, and then sort them in chronological order to ensure the latest post appears at the top.


```typescript
/* util/notion.ts */
import { BlogPost } from "../types/notion";

// Filter unpublished articles from the results
export function filterPosts(posts: BlogPost[]) {
  const publishedPosts = posts.filter(
    (post) => post.properties.published.checkbox
  );

  return publishedPosts;
};

// Sort posts in chronological order (newest first)
export function sortPosts(posts: BlogPost[]) {
  return posts.sort((a, b) => {
    let dateA = new Date(a.properties.date.date.start).getTime();
    let dateB = new Date(b.properties.date.date.start).getTime();

    return dateB - dateA;
  });
}
```


```typescript
/* /pages/index.tsx */

import { GetStaticProps } from "next";

export const getStaticProps: GetStaticProps = async () => {
  const posts = await getPosts();
  const publishedPosts = filterPosts(posts);
  const sortedPosts = sortPosts(publishedPosts);

  // This prevents the files being created on every local build
  if (process.env.NODE_ENV === "production") {
    await createPosts(posts);
  }

  return {
    props: {
      posts: sortedPosts,
    },
  };
};
```


We can now render the posts on the homepage by mapping over the results and returning an article for each post. We’ll display the title, the abstract as a description, the publish date, any relevant tags, and a link to allow the user to navigate to the post to read more.


```typescript
/* pages/index.tsx */

type Props = {
  posts: BlogPost[];
};

export default function Home({ posts }: Props) {
  return (
    <main>
      <h1>ISR Notion Example</h1>

      <section>
        <h2>Blog posts</h2>

        {posts.map((post) => {
          const title = post.properties.page.title[0].plain_text;
          const description = post.properties.abstract.rich_text[0].plain_text;
          const publishDate = post.properties.date.date.start;
          const url = `/${post.properties.slug.rich_text[0].plain_text}`;
          const tags = post.properties.tags.multi_select
            .map(({ name }) => name)
            .join(", ");

          return (
            <article key={post.id}>
              <a href={url}>
                <h3>{title}</h3>
              </a>

              <p>{description}</p>

              <ul>
                <li>Published: {publishDate}</li>
                <li>Tags: {tags}</li>
              </ul>
            </article>
          );
        })}
      </section>
    </main>
  );
}
```


**Website - Display one post**


Now that we display all posts to the user, let’s create a page for each blog post. Since the website is not aware of the posts, we’ll need to set up [dynamic routing](https://nextjs.org/docs/routing/dynamic-routes). We can do this by creating an `[id].tsx` file, retrieving the post information in the getStaticProps method, and use the [getStaticPaths](https://nextjs.org/docs/basic-features/data-fetching/get-static-paths) function to statically pre-render the dynamic content.


Let’s start by retrieving post data from it’s respective file. We’ll need to parse the markdown input into HTML content. We can do this using the [remark](https://www.npmjs.com/package/remark) npm package. Once the data has been serialised, we convert the file contents to a string to be passed to the post page as a prop.


```typescript
/* util/notion.ts */

import * as fs from "fs";
import { remark } from "remark";
import mdx from "remark-mdx";

const POSTS_DIR = path.join(process.cwd(), "posts");

export async function getPostData(id: string) {
  const fullPath = path.join(POSTS_DIR, `${id}.mdx`);
  const fileContents = fs.readFileSync(fullPath, "utf8");
  const processedContent = await remark().use(mdx).process(fileContents);
  const contentHtml = processedContent.toString();

  return contentHtml;
}
```


```typescript
/* [id].tsx */

import { GetStaticProps } from "next";
import ReactMarkdown from "react-markdown";
import remarkMdx from "remark-mdx";

export const getStaticProps: GetStaticProps = async ({ params }) => {
  const postData = await getPostData(params.id as string);

  return {
    props: {
      postData,
    },
  };
};

export default function BlogPost({ postData }: Props) {
  return (
    <main>
      <ReactMarkdown remarkPlugins={[remarkMdx]}>{postData}</ReactMarkdown>
    </main>
  );
}
```


Since we’ll be statically pre-rendering the pages that use dynamic routes, 


```typescript
/* lib/notion.ts */

const POSTS_DIR = path.join(process.cwd(), "posts");

export function getPostIds() {
  const fileNames = fs.readdirSync(POSTS_DIR);

  return fileNames.map((fileName) => {
    return {
      params: {
        id: fileName.replace(/\.mdx$/, ""),
      },
    };
  });
}
```


```typescript
/* [id].tsx */

export const getStaticPaths: GetStaticPaths = async () => {
  const paths = getPostIds();

  return {
    paths,
    fallback: false,
  };
};
```


**Next JS: ISR**

- This section will outline one of Next JS’s latest features, [Incremental Static Generation](https://vercel.com/docs/concepts/incremental-static-regeneration/overview). ISR allows developers the ability to update static content instantly without needing a full site rebuild. This is perfect for maintenance, as updating the Notion article will publish the latest copy to the personal website without redeploying, whilst providing LogRocket with a versioned update for their site.

**Notion: Feedback and review lifecycle**

- This section will outline the process of draft submission to LogRocket and the feedback process. It will detail Notion’s versioning and comments functionality. I love the meta idea of incorporating the review of this article into the article itself.

**Conclusion**

